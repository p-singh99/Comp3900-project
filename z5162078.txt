Week 1
The group was formed on Thursday. We then held a meeting at around 6 and made an initial set of user stories that covered all the base requirements of the 
project (UltraCast). We then also scheduled a meeting to take place on the night after the lecture.

Week 2
After watching the lectures we got into a meeting together and then transferred all of the user stories into Jira and made acceptance criteria which we all
collaborated upon.

Week 3
We had a meeting on Monday to discuss where we are with the project proposal. After that we started on the storyboarding. I had to leave mid-way urgently but
came back at the end to discuss our next meeting and and what our plans are.
We met again during our tutorial slot where we again discussed what aspects of the project proposal we are still missing and assigned people to complete them.
I made a start on an ER diagram and a UML diagram. That night we went through all of our user stories and did scrum poker to assign story points.
On Friday, we met again to finally grab all the diagrams and documents and then I went on putting them all together and into the project proposal. I wrote up
all the user stories in a readable format for the proposal and also answered things like how the user stories answered the project objectives and any novelty
functions we had in the user stories.
We met up on final time on Saturday to confirm everything on the proposal
I submitted the documents after some edits from the team members submitted on Sunday morning and afternoon.

Week 4
I started work on the searching functionss and algorithms.

Week 5
I continued working on the database. I improved the sql schema and added a python script that populates and depopulates the database with test data, based on real podcast rss feeds.
I also helped with troubleshooting some problems with the search functionality. I did a bit on the description page for downloading the podcast episodes but justin already implemented it by the time I finished it (and his implementation was better).
For next week: Keep going on rss parsing, maybe add more podcast details/episode details to the database? I also need to learn react so I can help more with the frontend stuff.

Week 6
Spent a fair bit of time making an rss scraper so the database would have a bunch of podcasts in it (ended up with 2000+ podcasts). The code will be useful for later when we allow users to add their own rss feeds to the database.
Also began work on the playback on the front end, but I'm still learning react so I didn't get much of that done.
For next week: Keep working on playback

Week 7
Spent more time working with the data in the database. I ran a script to properly extract categories from the rss feeds and store them all in the database. Previously my script would only extract 1 category and that was causing issues for the recommendation algorithm. The script to extract categories took over 5 hours to run on all 2000 podcasts! Then spent more time going through the podcasts again to add the raw xml data for each, so it's faster to get it from the frontend.
Finished off the playback so now it saves progress as it plays through and resumes where the user left off.
For next week: the next sprint starts!
